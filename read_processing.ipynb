{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from subprocess import Popen\n",
    "from time import sleep, time\n",
    "import signal\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to process files:\n",
      "\t\tCAGATC.fastq.gz\n",
      "\t\tGCAGCT.fastq.gz\n",
      "\t\tATCAGT.fastq\n",
      "\n",
      "Using 32/96 cores for each sample.\n",
      "Data will be output to /home/anthony/profiling_pipeline/sample_data/output/\n"
     ]
    }
   ],
   "source": [
    "fastq_dir = \"/home/anthony/cap_binding_pulldown/profiling/fastq/\"\n",
    "output_dir = \"/home/anthony/profiling_pipeline/sample_data\"\n",
    "available_cores = 96\n",
    "star_ncRNA_dir = \"/home/anthony/reference_genome/STAR_index_ncRNA/\"\n",
    "star_genome_dir = \"/home/anthony/reference_genome/STAR_index_ncRNA/\"\n",
    "\n",
    "fastq_dir += \"/\" if not fastq_dir.endswith(\"/\") else \"\"\n",
    "output_dir += \"/\" if not output_dir.endswith(\"/\") else \"\"\n",
    "\n",
    "#set up folder structure for output\n",
    "if os.access(output_dir, os.F_OK):\n",
    "    if not os.access(output_dir+\"output\", os.F_OK):\n",
    "        os.chdir(output_dir)\n",
    "        os.mkdir(\"output\")\n",
    "        os.mkdir(output_dir+\"/output/logs\")\n",
    "        os.mkdir(output_dir+\"/output/logs/pipeline_completion\")\n",
    "        os.mkdir(output_dir+\"/output/deduplicated\")\n",
    "        os.mkdir(output_dir+\"/output/trimmed\")\n",
    "        os.mkdir(output_dir+\"/output/ncRNA_aligned\")\n",
    "        os.mkdir(output_dir+\"/output/genome_aligned\")\n",
    "    output_dir += \"output/\"\n",
    "else:\n",
    "    print(\"WARNING:\", output_dir, \"does not exist.\")\n",
    "if not os.access(output_dir, os.F_OK):\n",
    "    print(\"WARNING:\", fastq_dir, \"does not exist.\")\n",
    "\n",
    "#check file endings for correct data processing.\n",
    "filenames = os.listdir(fastq_dir)\n",
    "fastq_files = []\n",
    "for filename in filenames:\n",
    "    if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "        fastq_files.append(filename)\n",
    "\n",
    "#calculate the number of cores by dividing available cores by number of samples.\n",
    "numcores = max(available_cores//len(fastq_files), 1)\n",
    "\n",
    "print(\"Ready to process files:\")\n",
    "[print(\"\\t\\t\"+file) for file in fastq_files]\n",
    "print(\"\\nUsing\", str(numcores)+\"/\"+str(available_cores), \"cores for each sample.\")\n",
    "print(\"Data will be output to\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines process handler for running one sample through the pipeline\n",
    "class run_one_sample():\n",
    "    '''handles the running of one sample through the entire pipeline. \n",
    "    This class should be called by an individual thread. It will output stdout/stderr \n",
    "    readouts from the individual steps in the .../output/logs/ folder.\n",
    "    \n",
    "    It also uses a simple text log to pick up where the sample left off if the pipeline \n",
    "    fails. This log is stored in .../output/logs/pipeline_completion/\n",
    "    \n",
    "    The self.check method will terminate the run and kill all running process groups if\n",
    "    one of the processes in this thread returns an exit code other than 0, or if any\n",
    "    other thread changes the global kill_pipeline variable to True. Default behavior is \n",
    "    to set kill_pipeline to True whenever any thread fails, thus halting processing of \n",
    "    all samples.\n",
    "    \n",
    "    On completion, each thread will add one to the global samples_done counter, to \n",
    "    let the main thread know when all are finished.\n",
    "    '''\n",
    "    def __init__(self, filename):\n",
    "        global kill_pipeline\n",
    "        global samples_done\n",
    "        global star_ncRNA_dir\n",
    "        global star_genome_dir\n",
    "        global fastq_dir\n",
    "        global output_dir\n",
    "        global numcores\n",
    "        self.star_ncRNA_dir = star_ncRNA_dir\n",
    "        self.star_genome_dir = star_genome_dir\n",
    "        self.fastq_dir = fastq_dir\n",
    "        self.filename = filename\n",
    "        self.output_dir = output_dir\n",
    "        self.numcores = numcores\n",
    "        self.killflag = False\n",
    "        match = re.search(\"(.+)(\\.fastq|\\.fastq\\.gz)$\", self.filename)\n",
    "        self.prefix = match.group(1)\n",
    "        self.suffix = match.group(2)\n",
    "        self.steps = [\"initiate\", \"deduplicate\", \"trim\", \"align_ncRNA\", \"align_genome\", \"sort\", \"index\"] \n",
    "        if not os.access(output_dir+\"logs/pipeline_completion/\"+self.prefix+\"_completion_log.txt\", os.F_OK):\n",
    "            self.current_step = 0\n",
    "        else:\n",
    "            self.completion = open(output_dir+\"/logs/\"+self.prefix+\"_completion_log.txt\", \"r\")\n",
    "            self.current_step = self.steps.index(self.completion.readlines()[-1].strip())\n",
    "            print(\"current_step\", self.current_step)\n",
    "            self.completion.close()\n",
    "        \n",
    "        with open(output_dir+\"/logs/\"+self.prefix+\"_stdout.txt\", \"a\") as self.stdout, \\\n",
    "            open(output_dir+\"/logs/pipeline_completion/\"+self.prefix+\"_completion_log.txt\", \"a\") as self.completion:\n",
    "            try:\n",
    "                self.proc = self.deduplicate(fastq_dir, output_dir, self.filename, numcores)\n",
    "                self.check(self.proc)\n",
    "                self.proc = self.trim_reads(output_dir, self.filename, numcores)\n",
    "                self.check(self.proc)\n",
    "                self.proc = self.align_ncRNA(output_dir, self.filename, numcores)\n",
    "                self.check(self.proc)\n",
    "                self.proc = self.align_genome(output_dir, self.filename, numcores)\n",
    "                self.check(self.proc)\n",
    "                self.proc = self.samtools_sort(output_dir, numcores)\n",
    "                self.check(self.proc)\n",
    "                self.proc = self.samtools_index(output_dir)\n",
    "                self.check(self.proc)\n",
    "                samples_done += 1\n",
    "            except:\n",
    "                self.killflag = True\n",
    "                kill_pipeline = True\n",
    "                samples_done += 1 \n",
    "                try:\n",
    "                    os.killpg(os.getpgid(self.proc.pid), signal.SIGTERM)\n",
    "                except ProcessLookupError:\n",
    "                    pass\n",
    "                raise\n",
    "    \n",
    "    def deduplicate(self, fastq_dir, output_dir, filename, numcores):\n",
    "        '''deduplicate ribosome profiling reads using dedupe.sh from \n",
    "        the BBTools suite.\n",
    "        '''\n",
    "        if self.killflag == False and self.current_step == 0:\n",
    "            self.stdout.write(\"Deduplicate\\n\"+\"\".join([\"-\"]*20)+\"\\n\\n\")\n",
    "            self.stdout.flush()\n",
    "            dedupe_dir = output_dir+\"deduplicated/\"+self.prefix+\"/\"\n",
    "            if not os.access(dedupe_dir, os.F_OK):\n",
    "                os.mkdir(dedupe_dir)\n",
    "            return Popen([\n",
    "                \"dedupe.sh\",\n",
    "                \"in=\"+fastq_dir+filename,\n",
    "                \"out=\"+dedupe_dir+self.prefix+\".deduped\"+self.suffix,\n",
    "                \"absorbmatch=t\", #absorb exact matches of contigs\n",
    "                \"absorbcontainment=f\", #do not absorb full containments of contigs\n",
    "                \"absorbrc=f\", #do not absorb reverse-compliments\n",
    "                \"threads=\"+str(numcores),\n",
    "            ], stdout=self.stdout, stderr=self.stdout, preexec_fn=os.setsid)\n",
    "        else: \n",
    "            return 0\n",
    "    \n",
    "    def trim_reads(self, output_dir, filename, numcores):\n",
    "        '''Trim adapters and low quality regions from reads using bbduk.sh\n",
    "        from the BBTools suite.\n",
    "        '''\n",
    "        if self.killflag == False and self.current_step == 1:\n",
    "            self.stdout.write(\"\\n\\nTrim Reads\\n\"+\"\".join([\"-\"]*20)+\"\\n\\n\")\n",
    "            self.stdout.flush()\n",
    "            dedupe_dir = output_dir+\"deduplicated/\"+self.prefix+\"/\"\n",
    "            trimmed_dir = output_dir+\"trimmed/\"+self.prefix+\"/\"\n",
    "            if not os.access(trimmed_dir, os.F_OK):\n",
    "                os.mkdir(trimmed_dir)\n",
    "                os.mkdir(trimmed_dir+\"failedQC\")\n",
    "            return Popen([\n",
    "                \"bbduk.sh\",\n",
    "                \"in=\"+dedupe_dir+self.prefix+\".deduped\"+self.suffix,\n",
    "                \"out=\"+trimmed_dir+self.prefix+\".trimmed\"+self.suffix,\n",
    "                \"outm=\"+trimmed_dir+\"failedQC/\"+self.prefix+\".failedQC\"+self.suffix,\n",
    "                \"refstats=\"+trimmed_dir+\"trimming_stats.txt\",\n",
    "                \"literal=NNNNNNCACTCGGGCACCAAGGAC\",\n",
    "                \"k=12\", # this parameter sets the minimum kmer being trimmed. \n",
    "                                      #Longer = more specific, shorter = more sensitive\n",
    "                \"copyundefined=t\",\n",
    "                \"ktrim=r\",\n",
    "                \"forcetrimleft=4\", #removes random barcode on left of reads.\n",
    "                \"minavgquality=10\",\n",
    "                \"minlength=10\",\n",
    "                \"threads=\"+str(numcores),\n",
    "            ],\n",
    "            stdout=self.stdout, stderr=self.stdout, preexec_fn=os.setsid)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def align_ncRNA(self, output_dir, filename, numcores):\n",
    "        '''Align reads to ncRNA using STAR. ncRNA fasta downloaded from Ensembl.\n",
    "        Output unaligned reads.\n",
    "        '''\n",
    "        if self.killflag == False and self.current_step == 2:\n",
    "            self.stdout.write(\"\\n\\nAlign to ncRNA\\n\"+\"\".join([\"-\"]*20)+\"\\n\\n\")\n",
    "            self.stdout.flush()\n",
    "            trimmed_dir = output_dir+\"trimmed/\"+self.prefix+\"/\"\n",
    "            ncRNA_aligned_dir = output_dir+\"ncRNA_aligned/\"+self.prefix+\"/\"\n",
    "            if not os.access(ncRNA_aligned_dir, os.F_OK):\n",
    "                os.mkdir(ncRNA_aligned_dir)\n",
    "            command = [\n",
    "                \"STAR\",\n",
    "                \"--runThreadN\", str(numcores),\n",
    "                \"--genomeDir\", self.star_ncRNA_dir,\n",
    "                \"--readFilesIn\", trimmed_dir+self.prefix+\".trimmed\"+self.suffix,\n",
    "                \"--outFileNamePrefix\", ncRNA_aligned_dir+self.prefix+\"_\",\n",
    "                \"--outSAMtype\", \"BAM\", \"Unsorted\",\n",
    "                \"--outReadsUnmapped\", \"Fastx\",\n",
    "            ]\n",
    "            if self.suffix == \".fastq.gz\":\n",
    "                command.extend([\"--readFilesCommand\", \"gunzip\"])\n",
    "            return Popen(command, stderr=self.stdout, stdout=self.stdout, \n",
    "                         preexec_fn=os.setsid)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def align_genome(self, output_dir, filename, numcores):\n",
    "        '''Align remaining reads to genome.\n",
    "        '''\n",
    "        if self.killflag == False and self.current_step == 3:\n",
    "            self.stdout.write(\"\\n\\nAlign to genome\\n\"+\"\".join([\"-\"]*20)+\"\\n\\n\")\n",
    "            self.stdout.flush()\n",
    "            ncRNA_aligned_dir = output_dir+\"ncRNA_aligned/\"+self.prefix+\"/\"\n",
    "            tx_aligned_dir = output_dir+\"genome_aligned/\"+self.prefix+\"/\"\n",
    "            if not os.access(tx_aligned_dir, os.F_OK):\n",
    "                os.mkdir(tx_aligned_dir)\n",
    "            command = [\n",
    "                \"STAR\",\n",
    "                \"--runThreadN\", str(self.numcores),\n",
    "                \"--genomeDir\", self.star_genome_dir,\n",
    "                \"--readFilesIn\", ncRNA_aligned_dir+self.prefix+\"_Unmapped.out.mate1\",\n",
    "                \"--outFileNamePrefix\", tx_aligned_dir+self.prefix+\"_\",\n",
    "                \"--outSAMtype\", \"BAM\", \"Unsorted\",\n",
    "                \"--outReadsUnmapped\", \"Fastx\",\n",
    "            ]\n",
    "            return Popen(command, stderr=self.stdout, stdout=self.stdout,\n",
    "                         preexec_fn=os.setsid)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def samtools_sort(self, output_dir, numcores):\n",
    "        '''Sort BAM file from STAR ouput.\n",
    "        '''\n",
    "        if self.killflag == False and self.current_step == 4:\n",
    "            self.stdout.write(\"\\n\\nSort BAM file\\n\"+\"\".join([\"-\"]*20)+\"\\n\\n\")\n",
    "            self.stdout.flush()\n",
    "            return Popen([\n",
    "                \"samtools\",\n",
    "                \"sort\",\n",
    "                \"-@\", str(numcores),\n",
    "                \"-f\", #use prefix as full file name\n",
    "                output_dir+\"genome_aligned/\"+self.prefix+\"/\"+self.prefix+\"_Aligned.out.bam\",\n",
    "                output_dir+\"genome_aligned/\"+self.prefix+\"/\"+self.prefix+\"_Aligned.out.sorted.bam\"\n",
    "            ], stderr=self.stdout, stdout=self.stdout, preexec_fn=os.setsid)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def samtools_index(self, output_dir):\n",
    "        '''Index BAM file from STAR output\n",
    "        '''\n",
    "        if self.killflag == False and self.current_step == 5:\n",
    "            self.stdout.write(\"\\n\\nIndex BAM file\\n\"+\"\".join([\"-\"]*20)+\"\\n\\n\")\n",
    "            self.stdout.flush()\n",
    "            try:\n",
    "                os.remove(output_dir+\"genome_aligned/\"+self.prefix+\"/\"+self.prefix+\"_Aligned.out.bam\",)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "            return Popen([\n",
    "                \"samtools\",\n",
    "                \"index\",\n",
    "                output_dir+\"genome_aligned/\"+self.prefix+\"/\"+self.prefix+\"_Aligned.out.sorted.bam\"\n",
    "            ], stderr=self.stdout, stdout=self.stdout, preexec_fn=os.setsid)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "    def check(self, proc):\n",
    "        '''Poll Popen processes returned by each method to determine if a nonzero\n",
    "        error code was returned. If so, kill process group and set global kill_pipeline\n",
    "        to True, signalling to other processing threads to shut down as well.\n",
    "        Polling happens every 1 second.\n",
    "        '''\n",
    "        global kill_pipeline\n",
    "        try:\n",
    "            exit_code = proc.poll()\n",
    "            while exit_code == None:\n",
    "                exit_code = proc.poll()\n",
    "                sleep(1)\n",
    "                if kill_pipeline == True:\n",
    "                    self.killflag = True\n",
    "                if self.killflag == True:\n",
    "                    os.killpg(os.getpgid(proc.pid), signal.SIGTERM)\n",
    "            else:\n",
    "                if exit_code != 0:\n",
    "                    self.killflag = True\n",
    "                    kill_pipeline = True\n",
    "                else:\n",
    "                    self.current_step += 1\n",
    "                    self.completion.write(self.steps[self.current_step]+\"\\n\")\n",
    "        except (AttributeError, ProcessLookupError): \n",
    "            #necessary to catch errors from methods returning 0 if self.killflag = True\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Running...\n",
      "Pipeline finished successfully!\n",
      "Run time: 6.74 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "kill_pipeline = False\n",
    "samples_done = 0\n",
    "sample_runs = {}\n",
    "\n",
    "#start threads for running each sample through the pipeline\n",
    "for filename in fastq_files:\n",
    "    sample_runs[filename] = Thread(target=run_one_sample, args=(filename,))\n",
    "    sample_runs[filename].start()\n",
    "    \n",
    "print(\"Pipeline Running...\")\n",
    "\n",
    "#Check every 1 sec whether the pipeline is finished and report wether it's been terminated.\n",
    "try:\n",
    "    while samples_done != len(fastq_files):\n",
    "        sleep(1)\n",
    "    else:\n",
    "        if kill_pipeline == False:\n",
    "            print(\"Pipeline finished successfully!\")\n",
    "        else:\n",
    "            print(\"Run terminated. Check for errors\")\n",
    "except:\n",
    "    kill_pipeline = True  #allows KeyboardInterrupt to kill pipeline\n",
    "    raise\n",
    "\n",
    "runtime = time() - start_time\n",
    "if runtime > 60:\n",
    "    mins = round(runtime/60, 2)\n",
    "    print(\"Run time:\", mins, \"minutes\")\n",
    "else:\n",
    "    secs = round(runtime, 2)\n",
    "    print(\"Run time:\", secs, \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
